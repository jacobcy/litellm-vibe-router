#!/usr/bin/env python3
"""
LiteLLM Intelligent Router Plugin
å®ç°æ™ºèƒ½è·¯ç”± + é™æµå›è½ + ç®€å•ä»»åŠ¡é™çº§

è·¯ç”±é€»è¾‘ï¼š
1. ç®€å•ä»»åŠ¡ (å¤æ‚åº¦ < 50): ç›´æ¥è·¯ç”±åˆ°è½»é‡çº§æ¨¡å‹
2. å¤æ‚ä»»åŠ¡ (å¤æ‚åº¦ >= 50): ä½¿ç”¨é»˜è®¤æ¨¡å‹
3. é™æµ/å¤±è´¥: LiteLLM router è‡ªåŠ¨ fallback åˆ°ä¸‹ä¸€çº§æ¨¡å‹

Fallback é“¾ (auto-chat ä¸ºä¾‹):
    openai/gpt-5 (ä¸»æ¨¡å‹) â†’ gpt-5 (é™æµå›è½)
"""

import sys
import time
from typing import Optional, Dict, Any, List, Literal, Union

# Initialize logging immediately
def _log(message: str, level: str = "INFO"):
    """Thread-safe logging to stderr"""
    timestamp = time.strftime("%H:%M:%S")
    sys.stderr.write(f"[{timestamp}] [VIBE-ROUTER] [{level}] {message}\n")
    sys.stderr.flush()

_log("=" * 70)
_log("Plugin module loading...")
_log("=" * 70)

try:
    from litellm.integrations.custom_logger import CustomLogger
    from litellm.proxy.proxy_server import UserAPIKeyAuth, DualCache
    import litellm
    _log("âœ“ LiteLLM imports successful")
except ImportError as e:
    _log(f"âœ— Import failed: {e}", "ERROR")
    raise


class VibeIntelligentRouter(CustomLogger):
    """
    æ™ºèƒ½è·¯ç”±å™¨ï¼š
    - å¤„ç†æ‰€æœ‰è™šæ‹Ÿæ¨¡å‹ (auto-chat, auto-codex, auto-claude)
    - æ ¹æ®å¤æ‚åº¦åˆ¤å®šç®€å•ä»»åŠ¡
    - ç®€å•ä»»åŠ¡ç›´æ¥è·¯ç”±åˆ°è½»é‡çº§æ¨¡å‹
    - LiteLLM router å¤„ç†é™æµå›è½
    """

    # ç®€å•ä»»åŠ¡ç›´æ¥è·¯ç”±çš„ç›®æ ‡æ¨¡å‹
    SIMPLE_TASK_TARGETS = {
        "auto-chat": "auto-chat-mini",
        # auto-codex å’Œ auto-claude ä¸é‡å†™ï¼Œè®© LiteLLM è‡ªå·±è·¯ç”±
    }

    def __init__(self):
        super().__init__()
        _log("Initializing VibeIntelligentRouter...")

        # ç®€å•ä»»åŠ¡æŒ‡æ ‡
        self.simple_indicators = {
            # Unix commands
            "ls", "cat", "pwd", "cd", "grep", "find", "echo", "cp", "mv", "rm",
            # Greetings
            "hi", "hello", "hey", "ä½ å¥½", "nihao",
            # Simple words
            "test", "ping", "status", "help"
        }

        # å¤æ‚ä»»åŠ¡æŒ‡æ ‡
        self.complex_indicators = {
            "implement", "algorithm", "architecture", "analyze", "design",
            "refactor", "optimize", "debug", "philosophical", "comprehensive",
            "concurrent", "distributed", "recursive"
        }

        _log(f"Supported virtual models: {list(self.SIMPLE_TASK_TARGETS.keys())}")
        _log("âœ“ Router initialized successfully")

    def _calculate_complexity(self, messages: List[Dict]) -> int:
        """
        è®¡ç®—æ¶ˆæ¯å¤æ‚åº¦è¯„åˆ†
        åˆ†æ•°è¶Šé«˜ = è¶Šå¤æ‚
        """
        if not messages:
            return 0

        score = 0

        # åˆ†ææœ€åä¸€æ¡æ¶ˆæ¯ (ç”¨æˆ·çš„è¯·æ±‚)
        last_msg = messages[-1]
        content = str(last_msg.get("content", "")).lower()

        # å› å­ 1: æ¶ˆæ¯é•¿åº¦ (è¶Šé•¿è¶Šå¤æ‚)
        content_length = len(content.strip())
        score += min(content_length, 200)  # ä¸Šé™ 200

        # å› å­ 2: ç®€å•æŒ‡æ ‡ (é™ä½åˆ†æ•°)
        simple_match = sum(1 for indicator in self.simple_indicators if indicator in content)
        if simple_match > 0:
            score -= 100 * simple_match

        # å› å­ 3: å¤æ‚æŒ‡æ ‡ (å¢åŠ åˆ†æ•°)
        complex_match = sum(1 for indicator in self.complex_indicators if indicator in content)
        if complex_match > 0:
            score += 150 * complex_match

        # å› å­ 4: ä»£ç å— (æŠ€æœ¯å†…å®¹ = å¤æ‚)
        if "```" in content or "def " in content or "function " in content:
            score += 100

        # å› å­ 5: å¤šå¥å­ (è¯¦ç»†è¯·æ±‚ = å¤æ‚)
        sentence_count = content.count('.') + content.count('?') + content.count('!')
        if sentence_count > 2:
            score += 50

        # å› å­ 6: å¯¹è¯å†å² (é•¿å¯¹è¯ = å¤æ‚)
        if len(messages) > 5:
            score += 30

        return max(0, score)  # ç¡®ä¿éè´Ÿ

    async def async_pre_call_hook(
        self,
        user_api_key_dict: UserAPIKeyAuth,
        cache: DualCache,
        data: Dict,
        call_type: Literal[
            "completion",
            "text_completion",
            "embeddings",
            "image_generation",
            "moderation",
            "audio_transcription"
        ],
    ) -> Optional[Union[Dict, Exception]]:
        """
        æ ¸å¿ƒ Hookï¼šåœ¨æ¨¡å‹åˆ«åæ˜ å°„ä¹‹åã€è·¯ç”±å™¨è§£æä¹‹å‰æ‰§è¡Œ

        æ‰§è¡Œé¡ºåº (æ¥è‡ª LiteLLM æºç ):
        1. è™šæ‹Ÿ key éªŒè¯
        2. æ¨¡å‹åˆ«åæ˜ å°„ (litellm.model_alias_map)
        3. â†’ async_pre_call_hook (æˆ‘ä»¬åœ¨è¿™é‡Œ) â†
        4. è·¯ç”±å™¨æ¨¡å‹è§£æ
        5. æ¨¡å‹éªŒè¯
        6. LiteLLM API è°ƒç”¨

        ======================================================================
        ğŸš§ NEXT PLAN: è‡ªåŠ¨å¤æ‚åº¦åˆ¤æ–­è·¯ç”±ï¼ˆæš‚æ—¶ç¦ç”¨ï¼‰
        ======================================================================
        å½“å‰ç­–ç•¥ï¼šè®©ç”¨æˆ·æ‰‹åŠ¨é€‰æ‹© auto-chat æˆ– auto-chat-mini
        åŸå› ï¼š
          1. å¤æ‚åº¦åˆ¤æ–­ç®—æ³•éœ€è¦æ›´å¤šæµ‹è¯•å’Œè°ƒä¼˜
          2. ç”¨æˆ·æ˜ç¡®é€‰æ‹©æ›´å¯é ã€å¯é¢„æµ‹
          3. å…ˆä¿è¯åŸºç¡€æœåŠ¡ç¨³å®šè¿è¡Œ
        æœªæ¥è®¡åˆ’ï¼š
          - æ”¶é›†æ›´å¤šçœŸå®è¯·æ±‚æ•°æ®
          - è®­ç»ƒæ›´å‡†ç¡®çš„å¤æ‚åº¦é¢„æµ‹æ¨¡å‹
          - æ·»åŠ ç”¨æˆ·åé¦ˆæœºåˆ¶ä¼˜åŒ–ç®—æ³•
        ======================================================================
        """
        try:
            _log(f"Hook triggered - call_type={call_type}")

            # å®‰å…¨æ£€æŸ¥
            if data is None:
                _log("WARNING: data is None, returning as-is", "WARN")
                return data

            # è·å–å½“å‰æ¨¡å‹
            original_model = data.get("model")
            _log(f"Original model: {original_model}")

            # ============================================================
            # ğŸš§ COMPLEXITY-BASED ROUTING (DISABLED)
            # ============================================================
            # å½“å‰ç›´æ¥é€ä¼ ï¼Œä¸åšä»»ä½•è·¯ç”±é‡å†™
            # ç”¨æˆ·éœ€è¦æ˜ç¡®é€‰æ‹©ï¼šauto-chatï¼ˆæ ‡å‡†ï¼‰æˆ– auto-chat-miniï¼ˆè½»é‡ï¼‰
            _log(f"Routing: PASSTHROUGH (user choice: {original_model})")
            
            # æ·»åŠ å…ƒæ•°æ®ç”¨äºå¯è§‚å¯Ÿæ€§
            if "metadata" not in data:
                data["metadata"] = {}
            data["metadata"]["routing_mode"] = "manual_selection"
            data["metadata"]["selected_model"] = original_model

            # ç›´æ¥è¿”å›åŸå§‹è¯·æ±‚ï¼Œç”± LiteLLM fallback é“¾å¤„ç†
            return data

            # ============================================================
            # ğŸ”½ ORIGINAL COMPLEXITY LOGIC (COMMENTED OUT FOR NEXT PLAN)
            # ============================================================
            # # åªå¤„ç†è™šæ‹Ÿæ¨¡å‹
            # if original_model not in self.SIMPLE_TASK_TARGETS:
            #     _log("Not a virtual model, passing through")
            #     return data
            #
            # # æå–æ¶ˆæ¯
            # messages = data.get("messages", [])
            # if not messages:
            #     _log("No messages found, using default model", "WARN")
            #     return data
            #
            # # è®¡ç®—å¤æ‚åº¦
            # complexity_score = self._calculate_complexity(messages)
            #
            # # å†³ç­–é˜ˆå€¼
            # COMPLEXITY_THRESHOLD = 50
            # is_simple = complexity_score < COMPLEXITY_THRESHOLD
            #
            # # ç®€å•ä»»åŠ¡ï¼šç›´æ¥è·¯ç”±åˆ°è½»é‡çº§æ¨¡å‹
            # if is_simple:
            #     target_model = self.SIMPLE_TASK_TARGETS[original_model]
            #     data["model"] = target_model
            #
            #     # æ·»åŠ å…ƒæ•°æ®ç”¨äºå¯è§‚å¯Ÿæ€§
            #     if "metadata" not in data:
            #         data["metadata"] = {}
            #     data["metadata"]["virtual_model"] = original_model
            #     data["metadata"]["routed_model"] = target_model
            #     data["metadata"]["complexity_score"] = complexity_score
            #     data["metadata"]["routing_reason"] = "simple_task"
            #
            #     _log("=" * 70)
            #     _log(f"âœ“ SIMPLE TASK ROUTING:")
            #     _log(f"  Virtual Model:    {original_model}")
            #     _log(f"  Target Model:      {target_model}")
            #     _log(f"  Complexity Score:  {complexity_score}")
            #     _log(f"  Decision:          SIMPLE â†’ Lightweight Model")
            #     _log(f"  Message Preview:   {messages[-1].get('content', '')[:60]}...")
            #     _log("=" * 70)
            # else:
            #     # å¤æ‚ä»»åŠ¡ï¼šä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼ŒLiteLLM router ä¼šå¤„ç†é™æµå›è½
            #     _log(f"Complex task (score={complexity_score}), using default model for fallback chain")
            #
            #     # æ·»åŠ å…ƒæ•°æ®
            #     if "metadata" not in data:
            #         data["metadata"] = {}
            #     data["metadata"]["virtual_model"] = original_model
            #     data["metadata"]["complexity_score"] = complexity_score
            #     data["metadata"]["routing_reason"] = "complex_task"
            #
            # # å…³é”®ï¼šå¿…é¡»è¿”å›ä¿®æ”¹åçš„ data å¯¹è±¡
            # return data

        except Exception as e:
            _log(f"ERROR in async_pre_call_hook: {str(e)}", "ERROR")
            import traceback
            _log(traceback.format_exc(), "ERROR")
            # è¿”å›æœªä¿®æ”¹çš„ data ä»¥é˜²æ­¢ç ´åè¯·æ±‚
            return data

    async def async_log_success_event(self, kwargs, response_obj, start_time, end_time):
        """è®°å½•æˆåŠŸçš„è·¯ç”±"""
        try:
            model = kwargs.get("model", "unknown")
            metadata = kwargs.get("metadata", {})
            virtual_model = metadata.get("virtual_model")

            if virtual_model:
                duration = (end_time - start_time).total_seconds()
                routing_reason = metadata.get("routing_reason", "default")
                _log(f"âœ“ SUCCESS: {virtual_model} -> {model} ({duration:.2f}s, reason={routing_reason})")
        except Exception as e:
            _log(f"Error in success logger: {e}", "ERROR")

    async def async_log_failure_event(self, kwargs, response_obj, start_time, end_time):
        """è®°å½•å¤±è´¥çš„è·¯ç”±"""
        try:
            model = kwargs.get("model", "unknown")
            metadata = kwargs.get("metadata", {})
            virtual_model = metadata.get("virtual_model", model)
            error = str(response_obj) if response_obj else "unknown"

            _log(f"âœ— FAILURE: {virtual_model} -> {model}", "ERROR")
            _log(f"  Error: {error[:200]}", "ERROR")
            _log(f"  (LiteLLM router will retry with fallback model if available)", "ERROR")
        except Exception as e:
            _log(f"Error in failure logger: {e}", "ERROR")


# Create singleton instance
_log("-" * 70)
_log("Creating router instance...")
router_instance = VibeIntelligentRouter()
_log("âœ“ router_instance created and ready")
_log("-" * 70)

# Export for LiteLLM callback system
proxy_handler_instance = router_instance
callback_handler = router_instance

_log("Plugin module loaded successfully âœ“")
